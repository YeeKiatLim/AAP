{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc87abd-caba-449f-8cfe-9ad5c21cfbb4",
   "metadata": {},
   "source": [
    "## Setting Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e8c59d-e0c7-447d-9c42-a6a290f78631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef3a078-6abd-4d50-b572-aeccfb0b5aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (4.41.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (0.30.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249eb2ca-9399-4e13-8725-37ecd52ec32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (2.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (0.23.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from evaluate) (23.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7af01fa-e32e-44d5-9b21-60d8421d30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy, matplotlib.pylot and panda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d5a1d7-fd65-4386-92df-043a64f2725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d010b215-ce16-4ed4-a250-785c675f7a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 4070 Laptop GPU'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1583c6-141f-472c-a639-21b55c1d03ec",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca2600c-abea-4ca5-b35c-32fa94393c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv-valid-test/sample-000000.mp3</td>\n",
       "      <td>without the dataset the article is useless</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv-valid-test/sample-000001.mp3</td>\n",
       "      <td>i've got to go to him</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv-valid-test/sample-000002.mp3</td>\n",
       "      <td>and you know it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv-valid-test/sample-000003.mp3</td>\n",
       "      <td>down below in the darkness were hundreds of pe...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv-valid-test/sample-000004.mp3</td>\n",
       "      <td>hold your nose to keep the smell from disablin...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>cv-valid-test/sample-003990.mp3</td>\n",
       "      <td>the old man opened his cape and the boy was st...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>cv-valid-test/sample-003991.mp3</td>\n",
       "      <td>in alchemy it's called the soul of the world</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>cv-valid-test/sample-003992.mp3</td>\n",
       "      <td>at that point in their lives everything is cle...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>cv-valid-test/sample-003993.mp3</td>\n",
       "      <td>he told them all to be seated</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>cv-valid-test/sample-003994.mp3</td>\n",
       "      <td>the restaurant was quite expensive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3995 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename  \\\n",
       "0     cv-valid-test/sample-000000.mp3   \n",
       "1     cv-valid-test/sample-000001.mp3   \n",
       "2     cv-valid-test/sample-000002.mp3   \n",
       "3     cv-valid-test/sample-000003.mp3   \n",
       "4     cv-valid-test/sample-000004.mp3   \n",
       "...                               ...   \n",
       "3990  cv-valid-test/sample-003990.mp3   \n",
       "3991  cv-valid-test/sample-003991.mp3   \n",
       "3992  cv-valid-test/sample-003992.mp3   \n",
       "3993  cv-valid-test/sample-003993.mp3   \n",
       "3994  cv-valid-test/sample-003994.mp3   \n",
       "\n",
       "                                                   text  up_votes  down_votes  \\\n",
       "0            without the dataset the article is useless         1           0   \n",
       "1                                 i've got to go to him         1           0   \n",
       "2                                       and you know it         1           0   \n",
       "3     down below in the darkness were hundreds of pe...         4           0   \n",
       "4     hold your nose to keep the smell from disablin...         2           0   \n",
       "...                                                 ...       ...         ...   \n",
       "3990  the old man opened his cape and the boy was st...         1           0   \n",
       "3991       in alchemy it's called the soul of the world         2           1   \n",
       "3992  at that point in their lives everything is cle...         3           0   \n",
       "3993                      he told them all to be seated         3           0   \n",
       "3994                 the restaurant was quite expensive         2           0   \n",
       "\n",
       "           age gender accent  duration  \n",
       "0          NaN    NaN    NaN       NaN  \n",
       "1     twenties   male    NaN       NaN  \n",
       "2          NaN    NaN    NaN       NaN  \n",
       "3     twenties   male     us       NaN  \n",
       "4          NaN    NaN    NaN       NaN  \n",
       "...        ...    ...    ...       ...  \n",
       "3990       NaN    NaN    NaN       NaN  \n",
       "3991       NaN    NaN    NaN       NaN  \n",
       "3992       NaN    NaN    NaN       NaN  \n",
       "3993       NaN    NaN    NaN       NaN  \n",
       "3994       NaN    NaN    NaN       NaN  \n",
       "\n",
       "[3995 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('cv-valid-test.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e585f58-b7c7-4f51-97fc-4149a78b2c11",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90e979a-a933-48d7-9704-31622ca38cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv-valid-test/sample-000000.mp3</td>\n",
       "      <td>without the dataset the article is useless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv-valid-test/sample-000001.mp3</td>\n",
       "      <td>i've got to go to him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv-valid-test/sample-000002.mp3</td>\n",
       "      <td>and you know it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cv-valid-test/sample-000003.mp3</td>\n",
       "      <td>down below in the darkness were hundreds of pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cv-valid-test/sample-000004.mp3</td>\n",
       "      <td>hold your nose to keep the smell from disablin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>cv-valid-test/sample-003990.mp3</td>\n",
       "      <td>the old man opened his cape and the boy was st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>cv-valid-test/sample-003991.mp3</td>\n",
       "      <td>in alchemy it's called the soul of the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>cv-valid-test/sample-003992.mp3</td>\n",
       "      <td>at that point in their lives everything is cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>cv-valid-test/sample-003993.mp3</td>\n",
       "      <td>he told them all to be seated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>cv-valid-test/sample-003994.mp3</td>\n",
       "      <td>the restaurant was quite expensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3995 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             filename  \\\n",
       "0     cv-valid-test/sample-000000.mp3   \n",
       "1     cv-valid-test/sample-000001.mp3   \n",
       "2     cv-valid-test/sample-000002.mp3   \n",
       "3     cv-valid-test/sample-000003.mp3   \n",
       "4     cv-valid-test/sample-000004.mp3   \n",
       "...                               ...   \n",
       "3990  cv-valid-test/sample-003990.mp3   \n",
       "3991  cv-valid-test/sample-003991.mp3   \n",
       "3992  cv-valid-test/sample-003992.mp3   \n",
       "3993  cv-valid-test/sample-003993.mp3   \n",
       "3994  cv-valid-test/sample-003994.mp3   \n",
       "\n",
       "                                                   text  \n",
       "0            without the dataset the article is useless  \n",
       "1                                 i've got to go to him  \n",
       "2                                       and you know it  \n",
       "3     down below in the darkness were hundreds of pe...  \n",
       "4     hold your nose to keep the smell from disablin...  \n",
       "...                                                 ...  \n",
       "3990  the old man opened his cape and the boy was st...  \n",
       "3991       in alchemy it's called the soul of the world  \n",
       "3992  at that point in their lives everything is cle...  \n",
       "3993                      he told them all to be seated  \n",
       "3994                 the restaurant was quite expensive  \n",
       "\n",
       "[3995 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[\"filename\", \"text\"]]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870fd2b6-f8a9-4097-910c-f8b9b0d6e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"English\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54406b2b-b7ce-4dd1-be08-634b876eb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch,processor=processor):\n",
    "     # load audio sample FROM PATH with specified sampling rate   \n",
    "    audio_array, sampling_rate = librosa.load(batch[\"filename\"], sr=16000, mono=True)\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio_array, sampling_rate=sampling_rate).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd1ad46b-515f-4e1a-8fe9-041287a270e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.apply(prepare_dataset,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd0cc21-20ff-4c7d-850b-8202bb17c939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.6730652, -0.6730652, -0.6730652, -0.67306...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 11820, 346, 264, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.7859349, -0.7859349, -0.7859349, -0.73237...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 600, 658, 281...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.79748297, -0.79748297, -0.79748297, -0.46...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 474, 291, 458, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-1.0352554, -1.0352554, -1.0352554, -1.03525...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 5093, 2507, 294, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.57676864, -0.57676864, -0.57676864, -0.44...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 4104, 428, 6690, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>[[-0.9301528, -0.9301528, -0.9301528, -0.93015...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 1331, 587, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>[[-0.7404628, -0.7404628, -0.7404628, -0.74046...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 259, 419, 339, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>[[-0.63220394, -0.63220394, -0.63220394, -0.63...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 267, 300, 935, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>[[-0.63407266, -0.63407266, -0.63407266, -0.63...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 675, 1907, 552, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>[[-0.80660975, -0.80660975, -0.80660975, -0.50...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 6383, 390, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3995 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input_features  \\\n",
       "0     [[-0.6730652, -0.6730652, -0.6730652, -0.67306...   \n",
       "1     [[-0.7859349, -0.7859349, -0.7859349, -0.73237...   \n",
       "2     [[-0.79748297, -0.79748297, -0.79748297, -0.46...   \n",
       "3     [[-1.0352554, -1.0352554, -1.0352554, -1.03525...   \n",
       "4     [[-0.57676864, -0.57676864, -0.57676864, -0.44...   \n",
       "...                                                 ...   \n",
       "3990  [[-0.9301528, -0.9301528, -0.9301528, -0.93015...   \n",
       "3991  [[-0.7404628, -0.7404628, -0.7404628, -0.74046...   \n",
       "3992  [[-0.63220394, -0.63220394, -0.63220394, -0.63...   \n",
       "3993  [[-0.63407266, -0.63407266, -0.63407266, -0.63...   \n",
       "3994  [[-0.80660975, -0.80660975, -0.80660975, -0.50...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [50258, 50259, 50359, 50363, 11820, 346, 264, ...  \n",
       "1     [50258, 50259, 50359, 50363, 72, 600, 658, 281...  \n",
       "2     [50258, 50259, 50359, 50363, 474, 291, 458, 30...  \n",
       "3     [50258, 50259, 50359, 50363, 5093, 2507, 294, ...  \n",
       "4     [50258, 50259, 50359, 50363, 4104, 428, 6690, ...  \n",
       "...                                                 ...  \n",
       "3990  [50258, 50259, 50359, 50363, 3322, 1331, 587, ...  \n",
       "3991  [50258, 50259, 50359, 50363, 259, 419, 339, 36...  \n",
       "3992  [50258, 50259, 50359, 50363, 267, 300, 935, 29...  \n",
       "3993  [50258, 50259, 50359, 50363, 675, 1907, 552, 4...  \n",
       "3994  [50258, 50259, 50359, 50363, 3322, 6383, 390, ...  \n",
       "\n",
       "[3995 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['input_features', 'labels']]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb14974-53b8-4911-9e4f-f1da261a26ac",
   "metadata": {},
   "source": [
    "### Splitting into Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "764afcb3-2162-4d85-a4e0-e73723b69631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e7df819-b15f-4f92-a3e6-12fce029468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-0.7396982, -0.7396982, -0.7396982, -0.56966...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 675, 1415, 281, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-1.1065807, -1.1065807, -1.1065807, -0.47670...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 390, 6359, 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-1.0652044, -1.0652044, -1.0652044, -0.87513...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 351, 291, 722, 42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-1.2244408, -1.2244408, -1.2244408, -1.22444...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 390, 13856, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.545365, -0.545365, -0.545365, -0.2958833,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 19096, 5800, 415,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>[[-0.53368616, -0.53368616, -0.53368616, -0.53...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 13162, 645, 1706,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>[[-1.0352554, -1.0352554, -1.0352554, -1.03525...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 5093, 2507, 294, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>[[-0.6904956, -0.6904956, -0.6904956, -0.62819...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 675, 14226, 264, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>[[-0.60460687, -0.60460687, -0.60460687, -0.45...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 474, 370, 7228, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>[[-0.76840913, -0.76840913, -0.76840913, -0.56...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 71, 1680, 279, 70...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3196 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         input_features  \\\n",
       "0     [[-0.7396982, -0.7396982, -0.7396982, -0.56966...   \n",
       "1     [[-1.1065807, -1.1065807, -1.1065807, -0.47670...   \n",
       "2     [[-1.0652044, -1.0652044, -1.0652044, -0.87513...   \n",
       "3     [[-1.2244408, -1.2244408, -1.2244408, -1.22444...   \n",
       "4     [[-0.545365, -0.545365, -0.545365, -0.2958833,...   \n",
       "...                                                 ...   \n",
       "3191  [[-0.53368616, -0.53368616, -0.53368616, -0.53...   \n",
       "3192  [[-1.0352554, -1.0352554, -1.0352554, -1.03525...   \n",
       "3193  [[-0.6904956, -0.6904956, -0.6904956, -0.62819...   \n",
       "3194  [[-0.60460687, -0.60460687, -0.60460687, -0.45...   \n",
       "3195  [[-0.76840913, -0.76840913, -0.76840913, -0.56...   \n",
       "\n",
       "                                                 labels  \n",
       "0     [50258, 50259, 50359, 50363, 675, 1415, 281, 9...  \n",
       "1     [50258, 50259, 50359, 50363, 72, 390, 6359, 49...  \n",
       "2     [50258, 50259, 50359, 50363, 351, 291, 722, 42...  \n",
       "3     [50258, 50259, 50359, 50363, 72, 390, 13856, 4...  \n",
       "4     [50258, 50259, 50359, 50363, 19096, 5800, 415,...  \n",
       "...                                                 ...  \n",
       "3191  [50258, 50259, 50359, 50363, 13162, 645, 1706,...  \n",
       "3192  [50258, 50259, 50359, 50363, 5093, 2507, 294, ...  \n",
       "3193  [50258, 50259, 50359, 50363, 675, 14226, 264, ...  \n",
       "3194  [50258, 50259, 50359, 50363, 474, 370, 7228, 2...  \n",
       "3195  [50258, 50259, 50359, 50363, 71, 1680, 279, 70...  \n",
       "\n",
       "[3196 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4dabd0b-f4d7-44d4-972d-6d7c2ca50606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-1.0096068, -1.0096068, -1.0096068, -1.00960...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 336, 436, 519, 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-1.0501065, -1.0501065, -1.0501065, -0.83016...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 5298, 291, 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.53549445, -0.53549445, -0.53549445, -0.53...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 49800, 18185, 337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.5928992, -0.5928992, -0.5928992, -0.59289...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 39380, 570, 300, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.686262, -0.686262, -0.64569473, -0.234107...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 5616, 603, 764, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>[[-0.8432269, -0.8432269, -0.8432269, -0.59362...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 18822, 291, 366, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>[[-1.0786912, -1.0786912, -1.0786912, -0.88296...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 15456, 390, 588, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>[[-1.2304549, -1.2304549, -1.2304549, -1.23045...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 1633, 362, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>[[-0.772483, -0.772483, -0.6983535, -0.0572773...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 534, 13416, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>[[-0.8870206, -0.8870206, -0.8870206, -0.88702...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 13966, 380, 291, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        input_features  \\\n",
       "0    [[-1.0096068, -1.0096068, -1.0096068, -1.00960...   \n",
       "1    [[-1.0501065, -1.0501065, -1.0501065, -0.83016...   \n",
       "2    [[-0.53549445, -0.53549445, -0.53549445, -0.53...   \n",
       "3    [[-0.5928992, -0.5928992, -0.5928992, -0.59289...   \n",
       "4    [[-0.686262, -0.686262, -0.64569473, -0.234107...   \n",
       "..                                                 ...   \n",
       "794  [[-0.8432269, -0.8432269, -0.8432269, -0.59362...   \n",
       "795  [[-1.0786912, -1.0786912, -1.0786912, -0.88296...   \n",
       "796  [[-1.2304549, -1.2304549, -1.2304549, -1.23045...   \n",
       "797  [[-0.772483, -0.772483, -0.6983535, -0.0572773...   \n",
       "798  [[-0.8870206, -0.8870206, -0.8870206, -0.88702...   \n",
       "\n",
       "                                                labels  \n",
       "0    [50258, 50259, 50359, 50363, 336, 436, 519, 46...  \n",
       "1    [50258, 50259, 50359, 50363, 72, 5298, 291, 64...  \n",
       "2    [50258, 50259, 50359, 50363, 49800, 18185, 337...  \n",
       "3    [50258, 50259, 50359, 50363, 39380, 570, 300, ...  \n",
       "4    [50258, 50259, 50359, 50363, 5616, 603, 764, 4...  \n",
       "..                                                 ...  \n",
       "794  [50258, 50259, 50359, 50363, 18822, 291, 366, ...  \n",
       "795  [50258, 50259, 50359, 50363, 15456, 390, 588, ...  \n",
       "796  [50258, 50259, 50359, 50363, 270, 1633, 362, 1...  \n",
       "797  [50258, 50259, 50359, 50363, 270, 534, 13416, ...  \n",
       "798  [50258, 50259, 50359, 50363, 13966, 380, 291, ...  \n",
       "\n",
       "[799 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.reset_index(drop=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b63aacc2-8b34-4faf-a0d1-580186d17728",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation, benchmark = train_test_split(test, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65729622-1973-4f07-8aa7-938ceea4cdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-1.1315699, -1.1315699, -1.1315699, -1.13156...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 9488, 2610,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.74414, -0.74414, -0.74414, -0.74414, -0.5...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 1902, 292, 1152, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.8293656, -0.8293656, -0.8293656, -0.59377...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 4286, 360, 561, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.7068156, -0.7068156, -0.7068156, -0.44695...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 3237, 3031,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.87031555, -0.87031555, -0.87031555, -0.87...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 306, 12674, 6869,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>[[-0.9255625, -0.9255625, -0.9255625, -0.92556...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 3237, 5694,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>[[-0.82639194, -0.82639194, -0.82639194, -0.82...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 266, 527, 636, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[[-0.73914635, -0.73914635, -0.73914635, -0.57...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 71, 3145, 732, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[[-0.5983442, -0.5983442, -0.5983442, 0.034376...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 20579, 456, 415, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>[[-1.045434, -1.045434, -1.045434, -0.5077677,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 71, 3159, 82, 295...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       input_features  \\\n",
       "0   [[-1.1315699, -1.1315699, -1.1315699, -1.13156...   \n",
       "1   [[-0.74414, -0.74414, -0.74414, -0.74414, -0.5...   \n",
       "2   [[-0.8293656, -0.8293656, -0.8293656, -0.59377...   \n",
       "3   [[-0.7068156, -0.7068156, -0.7068156, -0.44695...   \n",
       "4   [[-0.87031555, -0.87031555, -0.87031555, -0.87...   \n",
       "..                                                ...   \n",
       "75  [[-0.9255625, -0.9255625, -0.9255625, -0.92556...   \n",
       "76  [[-0.82639194, -0.82639194, -0.82639194, -0.82...   \n",
       "77  [[-0.73914635, -0.73914635, -0.73914635, -0.57...   \n",
       "78  [[-0.5983442, -0.5983442, -0.5983442, 0.034376...   \n",
       "79  [[-1.045434, -1.045434, -1.045434, -0.5077677,...   \n",
       "\n",
       "                                               labels  \n",
       "0   [50258, 50259, 50359, 50363, 3322, 9488, 2610,...  \n",
       "1   [50258, 50259, 50359, 50363, 1902, 292, 1152, ...  \n",
       "2   [50258, 50259, 50359, 50363, 4286, 360, 561, 8...  \n",
       "3   [50258, 50259, 50359, 50363, 3322, 3237, 3031,...  \n",
       "4   [50258, 50259, 50359, 50363, 306, 12674, 6869,...  \n",
       "..                                                ...  \n",
       "75  [50258, 50259, 50359, 50363, 3322, 3237, 5694,...  \n",
       "76  [50258, 50259, 50359, 50363, 266, 527, 636, 28...  \n",
       "77  [50258, 50259, 50359, 50363, 71, 3145, 732, 29...  \n",
       "78  [50258, 50259, 50359, 50363, 20579, 456, 415, ...  \n",
       "79  [50258, 50259, 50359, 50363, 71, 3159, 82, 295...  \n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = benchmark.reset_index(drop=True)\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd9fc81a-b332-40ad-9a9e-df6189eb926e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3186</th>\n",
       "      <th>3187</th>\n",
       "      <th>3188</th>\n",
       "      <th>3189</th>\n",
       "      <th>3190</th>\n",
       "      <th>3191</th>\n",
       "      <th>3192</th>\n",
       "      <th>3193</th>\n",
       "      <th>3194</th>\n",
       "      <th>3195</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_features</th>\n",
       "      <td>[[-0.7396982, -0.7396982, -0.7396982, -0.56966...</td>\n",
       "      <td>[[-1.1065807, -1.1065807, -1.1065807, -0.47670...</td>\n",
       "      <td>[[-1.0652044, -1.0652044, -1.0652044, -0.87513...</td>\n",
       "      <td>[[-1.2244408, -1.2244408, -1.2244408, -1.22444...</td>\n",
       "      <td>[[-0.545365, -0.545365, -0.545365, -0.2958833,...</td>\n",
       "      <td>[[-0.9114121, -0.9114121, -0.9114121, 0.167829...</td>\n",
       "      <td>[[-0.8647183, -0.8647183, -0.8647183, -0.86471...</td>\n",
       "      <td>[[-0.57422614, -0.57422614, -0.57422614, 0.134...</td>\n",
       "      <td>[[-0.79151523, -0.79151523, -0.79151523, -0.60...</td>\n",
       "      <td>[[-0.56270766, -0.56270766, -0.56270766, -0.56...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-1.2383907, -1.2383907, -1.2224436, -1.17380...</td>\n",
       "      <td>[[-1.0518277, -1.0518277, -1.0335014, -0.55342...</td>\n",
       "      <td>[[-0.80575323, -0.80575323, -0.80575323, -0.80...</td>\n",
       "      <td>[[-0.6096194, -0.6096194, -0.6096194, -0.60961...</td>\n",
       "      <td>[[-0.6775445, -0.6775445, -0.6775445, -0.56451...</td>\n",
       "      <td>[[-0.53368616, -0.53368616, -0.53368616, -0.53...</td>\n",
       "      <td>[[-1.0352554, -1.0352554, -1.0352554, -1.03525...</td>\n",
       "      <td>[[-0.6904956, -0.6904956, -0.6904956, -0.62819...</td>\n",
       "      <td>[[-0.60460687, -0.60460687, -0.60460687, -0.45...</td>\n",
       "      <td>[[-0.76840913, -0.76840913, -0.76840913, -0.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>[50258, 50259, 50359, 50363, 675, 1415, 281, 9...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 390, 6359, 49...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 351, 291, 722, 42...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 390, 13856, 4...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 19096, 5800, 415,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 539, 437, 360, 29...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 1445, 436, 434, 5...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 11176, 3144, 2203...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 311, 257, 22...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 2586, 295, 2...</td>\n",
       "      <td>...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 727, 978, 199...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 3440, 390, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 69, 1023, 561, 18...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 11176, 390, 264, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 1604, 577, 74...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 13162, 645, 1706,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 5093, 2507, 294, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 675, 14226, 264, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 474, 370, 7228, 2...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 71, 1680, 279, 70...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0     \\\n",
       "input_features  [[-0.7396982, -0.7396982, -0.7396982, -0.56966...   \n",
       "labels          [50258, 50259, 50359, 50363, 675, 1415, 281, 9...   \n",
       "\n",
       "                                                             1     \\\n",
       "input_features  [[-1.1065807, -1.1065807, -1.1065807, -0.47670...   \n",
       "labels          [50258, 50259, 50359, 50363, 72, 390, 6359, 49...   \n",
       "\n",
       "                                                             2     \\\n",
       "input_features  [[-1.0652044, -1.0652044, -1.0652044, -0.87513...   \n",
       "labels          [50258, 50259, 50359, 50363, 351, 291, 722, 42...   \n",
       "\n",
       "                                                             3     \\\n",
       "input_features  [[-1.2244408, -1.2244408, -1.2244408, -1.22444...   \n",
       "labels          [50258, 50259, 50359, 50363, 72, 390, 13856, 4...   \n",
       "\n",
       "                                                             4     \\\n",
       "input_features  [[-0.545365, -0.545365, -0.545365, -0.2958833,...   \n",
       "labels          [50258, 50259, 50359, 50363, 19096, 5800, 415,...   \n",
       "\n",
       "                                                             5     \\\n",
       "input_features  [[-0.9114121, -0.9114121, -0.9114121, 0.167829...   \n",
       "labels          [50258, 50259, 50359, 50363, 539, 437, 360, 29...   \n",
       "\n",
       "                                                             6     \\\n",
       "input_features  [[-0.8647183, -0.8647183, -0.8647183, -0.86471...   \n",
       "labels          [50258, 50259, 50359, 50363, 1445, 436, 434, 5...   \n",
       "\n",
       "                                                             7     \\\n",
       "input_features  [[-0.57422614, -0.57422614, -0.57422614, 0.134...   \n",
       "labels          [50258, 50259, 50359, 50363, 11176, 3144, 2203...   \n",
       "\n",
       "                                                             8     \\\n",
       "input_features  [[-0.79151523, -0.79151523, -0.79151523, -0.60...   \n",
       "labels          [50258, 50259, 50359, 50363, 270, 311, 257, 22...   \n",
       "\n",
       "                                                             9     ...  \\\n",
       "input_features  [[-0.56270766, -0.56270766, -0.56270766, -0.56...  ...   \n",
       "labels          [50258, 50259, 50359, 50363, 270, 2586, 295, 2...  ...   \n",
       "\n",
       "                                                             3186  \\\n",
       "input_features  [[-1.2383907, -1.2383907, -1.2224436, -1.17380...   \n",
       "labels          [50258, 50259, 50359, 50363, 72, 727, 978, 199...   \n",
       "\n",
       "                                                             3187  \\\n",
       "input_features  [[-1.0518277, -1.0518277, -1.0335014, -0.55342...   \n",
       "labels          [50258, 50259, 50359, 50363, 3322, 3440, 390, ...   \n",
       "\n",
       "                                                             3188  \\\n",
       "input_features  [[-0.80575323, -0.80575323, -0.80575323, -0.80...   \n",
       "labels          [50258, 50259, 50359, 50363, 69, 1023, 561, 18...   \n",
       "\n",
       "                                                             3189  \\\n",
       "input_features  [[-0.6096194, -0.6096194, -0.6096194, -0.60961...   \n",
       "labels          [50258, 50259, 50359, 50363, 11176, 390, 264, ...   \n",
       "\n",
       "                                                             3190  \\\n",
       "input_features  [[-0.6775445, -0.6775445, -0.6775445, -0.56451...   \n",
       "labels          [50258, 50259, 50359, 50363, 72, 1604, 577, 74...   \n",
       "\n",
       "                                                             3191  \\\n",
       "input_features  [[-0.53368616, -0.53368616, -0.53368616, -0.53...   \n",
       "labels          [50258, 50259, 50359, 50363, 13162, 645, 1706,...   \n",
       "\n",
       "                                                             3192  \\\n",
       "input_features  [[-1.0352554, -1.0352554, -1.0352554, -1.03525...   \n",
       "labels          [50258, 50259, 50359, 50363, 5093, 2507, 294, ...   \n",
       "\n",
       "                                                             3193  \\\n",
       "input_features  [[-0.6904956, -0.6904956, -0.6904956, -0.62819...   \n",
       "labels          [50258, 50259, 50359, 50363, 675, 14226, 264, ...   \n",
       "\n",
       "                                                             3194  \\\n",
       "input_features  [[-0.60460687, -0.60460687, -0.60460687, -0.45...   \n",
       "labels          [50258, 50259, 50359, 50363, 474, 370, 7228, 2...   \n",
       "\n",
       "                                                             3195  \n",
       "input_features  [[-0.76840913, -0.76840913, -0.76840913, -0.56...  \n",
       "labels          [50258, 50259, 50359, 50363, 71, 1680, 279, 70...  \n",
       "\n",
       "[2 rows x 3196 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.T\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c0cd02-c7ce-4ea9-8c7d-78cc0ba38360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>789</th>\n",
       "      <th>790</th>\n",
       "      <th>791</th>\n",
       "      <th>792</th>\n",
       "      <th>793</th>\n",
       "      <th>794</th>\n",
       "      <th>795</th>\n",
       "      <th>796</th>\n",
       "      <th>797</th>\n",
       "      <th>798</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_features</th>\n",
       "      <td>[[-1.0096068, -1.0096068, -1.0096068, -1.00960...</td>\n",
       "      <td>[[-1.0501065, -1.0501065, -1.0501065, -0.83016...</td>\n",
       "      <td>[[-0.53549445, -0.53549445, -0.53549445, -0.53...</td>\n",
       "      <td>[[-0.5928992, -0.5928992, -0.5928992, -0.59289...</td>\n",
       "      <td>[[-0.686262, -0.686262, -0.64569473, -0.234107...</td>\n",
       "      <td>[[-0.6876404, -0.6876404, -0.6876404, -0.68764...</td>\n",
       "      <td>[[-0.8542875, -0.8542875, -0.8542875, -0.85428...</td>\n",
       "      <td>[[-0.8479985, -0.8479985, -0.8479985, -0.84799...</td>\n",
       "      <td>[[-0.8816, -0.8816, -0.8816, -0.359483, -0.666...</td>\n",
       "      <td>[[-0.8577628, -0.8577628, -0.8577628, -0.74194...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.97213197, -0.97213197, -0.97213197, -0.97...</td>\n",
       "      <td>[[-1.1351261, -1.1351261, -0.9823216, -0.26160...</td>\n",
       "      <td>[[-0.64631915, -0.64631915, -0.64631915, -0.56...</td>\n",
       "      <td>[[-0.96042037, -0.96042037, -0.9181441, -0.564...</td>\n",
       "      <td>[[-0.42516565, -0.42516565, -0.42516565, -0.08...</td>\n",
       "      <td>[[-0.8432269, -0.8432269, -0.8432269, -0.59362...</td>\n",
       "      <td>[[-1.0786912, -1.0786912, -1.0786912, -0.88296...</td>\n",
       "      <td>[[-1.2304549, -1.2304549, -1.2304549, -1.23045...</td>\n",
       "      <td>[[-0.772483, -0.772483, -0.6983535, -0.0572773...</td>\n",
       "      <td>[[-0.8870206, -0.8870206, -0.8870206, -0.88702...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>[50258, 50259, 50359, 50363, 336, 436, 519, 46...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 5298, 291, 64...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 49800, 18185, 337...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 39380, 570, 300, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 5616, 603, 764, 4...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 474, 1310, 309, 2...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 13162, 434, 1009,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 311, 47976, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 259, 729, 1708, 5...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 5479, 360, 291, 5...</td>\n",
       "      <td>...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 6576, 281, 7...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 3428, 2573, 5...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 1194, 390, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 71, 521, 3953, 93...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 474, 415, 2067, 3...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 18822, 291, 366, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 15456, 390, 588, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 1633, 362, 1...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 534, 13416, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 13966, 380, 291, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 799 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              0    \\\n",
       "input_features  [[-1.0096068, -1.0096068, -1.0096068, -1.00960...   \n",
       "labels          [50258, 50259, 50359, 50363, 336, 436, 519, 46...   \n",
       "\n",
       "                                                              1    \\\n",
       "input_features  [[-1.0501065, -1.0501065, -1.0501065, -0.83016...   \n",
       "labels          [50258, 50259, 50359, 50363, 72, 5298, 291, 64...   \n",
       "\n",
       "                                                              2    \\\n",
       "input_features  [[-0.53549445, -0.53549445, -0.53549445, -0.53...   \n",
       "labels          [50258, 50259, 50359, 50363, 49800, 18185, 337...   \n",
       "\n",
       "                                                              3    \\\n",
       "input_features  [[-0.5928992, -0.5928992, -0.5928992, -0.59289...   \n",
       "labels          [50258, 50259, 50359, 50363, 39380, 570, 300, ...   \n",
       "\n",
       "                                                              4    \\\n",
       "input_features  [[-0.686262, -0.686262, -0.64569473, -0.234107...   \n",
       "labels          [50258, 50259, 50359, 50363, 5616, 603, 764, 4...   \n",
       "\n",
       "                                                              5    \\\n",
       "input_features  [[-0.6876404, -0.6876404, -0.6876404, -0.68764...   \n",
       "labels          [50258, 50259, 50359, 50363, 474, 1310, 309, 2...   \n",
       "\n",
       "                                                              6    \\\n",
       "input_features  [[-0.8542875, -0.8542875, -0.8542875, -0.85428...   \n",
       "labels          [50258, 50259, 50359, 50363, 13162, 434, 1009,...   \n",
       "\n",
       "                                                              7    \\\n",
       "input_features  [[-0.8479985, -0.8479985, -0.8479985, -0.84799...   \n",
       "labels          [50258, 50259, 50359, 50363, 270, 311, 47976, ...   \n",
       "\n",
       "                                                              8    \\\n",
       "input_features  [[-0.8816, -0.8816, -0.8816, -0.359483, -0.666...   \n",
       "labels          [50258, 50259, 50359, 50363, 259, 729, 1708, 5...   \n",
       "\n",
       "                                                              9    ...  \\\n",
       "input_features  [[-0.8577628, -0.8577628, -0.8577628, -0.74194...  ...   \n",
       "labels          [50258, 50259, 50359, 50363, 5479, 360, 291, 5...  ...   \n",
       "\n",
       "                                                              789  \\\n",
       "input_features  [[-0.97213197, -0.97213197, -0.97213197, -0.97...   \n",
       "labels          [50258, 50259, 50359, 50363, 270, 6576, 281, 7...   \n",
       "\n",
       "                                                              790  \\\n",
       "input_features  [[-1.1351261, -1.1351261, -0.9823216, -0.26160...   \n",
       "labels          [50258, 50259, 50359, 50363, 72, 3428, 2573, 5...   \n",
       "\n",
       "                                                              791  \\\n",
       "input_features  [[-0.64631915, -0.64631915, -0.64631915, -0.56...   \n",
       "labels          [50258, 50259, 50359, 50363, 3322, 1194, 390, ...   \n",
       "\n",
       "                                                              792  \\\n",
       "input_features  [[-0.96042037, -0.96042037, -0.9181441, -0.564...   \n",
       "labels          [50258, 50259, 50359, 50363, 71, 521, 3953, 93...   \n",
       "\n",
       "                                                              793  \\\n",
       "input_features  [[-0.42516565, -0.42516565, -0.42516565, -0.08...   \n",
       "labels          [50258, 50259, 50359, 50363, 474, 415, 2067, 3...   \n",
       "\n",
       "                                                              794  \\\n",
       "input_features  [[-0.8432269, -0.8432269, -0.8432269, -0.59362...   \n",
       "labels          [50258, 50259, 50359, 50363, 18822, 291, 366, ...   \n",
       "\n",
       "                                                              795  \\\n",
       "input_features  [[-1.0786912, -1.0786912, -1.0786912, -0.88296...   \n",
       "labels          [50258, 50259, 50359, 50363, 15456, 390, 588, ...   \n",
       "\n",
       "                                                              796  \\\n",
       "input_features  [[-1.2304549, -1.2304549, -1.2304549, -1.23045...   \n",
       "labels          [50258, 50259, 50359, 50363, 270, 1633, 362, 1...   \n",
       "\n",
       "                                                              797  \\\n",
       "input_features  [[-0.772483, -0.772483, -0.6983535, -0.0572773...   \n",
       "labels          [50258, 50259, 50359, 50363, 270, 534, 13416, ...   \n",
       "\n",
       "                                                              798  \n",
       "input_features  [[-0.8870206, -0.8870206, -0.8870206, -0.88702...  \n",
       "labels          [50258, 50259, 50359, 50363, 13966, 380, 291, ...  \n",
       "\n",
       "[2 rows x 799 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.T\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92fb68db-392d-422b-9573-6904cc15ec24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_features</th>\n",
       "      <td>[[-1.1315699, -1.1315699, -1.1315699, -1.13156...</td>\n",
       "      <td>[[-0.74414, -0.74414, -0.74414, -0.74414, -0.5...</td>\n",
       "      <td>[[-0.8293656, -0.8293656, -0.8293656, -0.59377...</td>\n",
       "      <td>[[-0.7068156, -0.7068156, -0.7068156, -0.44695...</td>\n",
       "      <td>[[-0.87031555, -0.87031555, -0.87031555, -0.87...</td>\n",
       "      <td>[[-1.3740661, -1.3740661, -1.277633, -0.649837...</td>\n",
       "      <td>[[-0.77064395, -0.77064395, -0.77064395, -0.24...</td>\n",
       "      <td>[[-0.99318385, -0.99318385, -0.99318385, -0.61...</td>\n",
       "      <td>[[-0.87945354, -0.87945354, -0.87945354, -0.43...</td>\n",
       "      <td>[[-0.86943305, -0.86943305, -0.86943305, -0.86...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[-0.84461737, -0.84461737, -0.84461737, -0.20...</td>\n",
       "      <td>[[-0.8953326, -0.8953326, -0.8953326, -0.89533...</td>\n",
       "      <td>[[-0.7832053, -0.7832053, -0.5498072, 0.148869...</td>\n",
       "      <td>[[-0.55103076, -0.55103076, -0.55103076, -0.55...</td>\n",
       "      <td>[[-0.5610559, -0.5610559, -0.5610559, -0.11793...</td>\n",
       "      <td>[[-0.9255625, -0.9255625, -0.9255625, -0.92556...</td>\n",
       "      <td>[[-0.82639194, -0.82639194, -0.82639194, -0.82...</td>\n",
       "      <td>[[-0.73914635, -0.73914635, -0.73914635, -0.57...</td>\n",
       "      <td>[[-0.5983442, -0.5983442, -0.5983442, 0.034376...</td>\n",
       "      <td>[[-1.045434, -1.045434, -1.045434, -0.5077677,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 9488, 2610,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 1902, 292, 1152, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 4286, 360, 561, 8...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 3237, 3031,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 306, 12674, 6869,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 390, 13856, 4...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 675, 2198, 257, 2...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 546, 538, 472, 26...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 72, 500, 380, 458...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 707, 1594, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 270, 632, 257, 14...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 2994, 412, 300, 5...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 5616, 458, 689, 7...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 13162, 6576, 281,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 3295, 1194,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 3322, 3237, 5694,...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 266, 527, 636, 28...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 71, 3145, 732, 29...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 20579, 456, 415, ...</td>\n",
       "      <td>[50258, 50259, 50359, 50363, 71, 3159, 82, 295...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               0   \\\n",
       "input_features  [[-1.1315699, -1.1315699, -1.1315699, -1.13156...   \n",
       "labels          [50258, 50259, 50359, 50363, 3322, 9488, 2610,...   \n",
       "\n",
       "                                                               1   \\\n",
       "input_features  [[-0.74414, -0.74414, -0.74414, -0.74414, -0.5...   \n",
       "labels          [50258, 50259, 50359, 50363, 1902, 292, 1152, ...   \n",
       "\n",
       "                                                               2   \\\n",
       "input_features  [[-0.8293656, -0.8293656, -0.8293656, -0.59377...   \n",
       "labels          [50258, 50259, 50359, 50363, 4286, 360, 561, 8...   \n",
       "\n",
       "                                                               3   \\\n",
       "input_features  [[-0.7068156, -0.7068156, -0.7068156, -0.44695...   \n",
       "labels          [50258, 50259, 50359, 50363, 3322, 3237, 3031,...   \n",
       "\n",
       "                                                               4   \\\n",
       "input_features  [[-0.87031555, -0.87031555, -0.87031555, -0.87...   \n",
       "labels          [50258, 50259, 50359, 50363, 306, 12674, 6869,...   \n",
       "\n",
       "                                                               5   \\\n",
       "input_features  [[-1.3740661, -1.3740661, -1.277633, -0.649837...   \n",
       "labels          [50258, 50259, 50359, 50363, 72, 390, 13856, 4...   \n",
       "\n",
       "                                                               6   \\\n",
       "input_features  [[-0.77064395, -0.77064395, -0.77064395, -0.24...   \n",
       "labels          [50258, 50259, 50359, 50363, 675, 2198, 257, 2...   \n",
       "\n",
       "                                                               7   \\\n",
       "input_features  [[-0.99318385, -0.99318385, -0.99318385, -0.61...   \n",
       "labels          [50258, 50259, 50359, 50363, 546, 538, 472, 26...   \n",
       "\n",
       "                                                               8   \\\n",
       "input_features  [[-0.87945354, -0.87945354, -0.87945354, -0.43...   \n",
       "labels          [50258, 50259, 50359, 50363, 72, 500, 380, 458...   \n",
       "\n",
       "                                                               9   ...  \\\n",
       "input_features  [[-0.86943305, -0.86943305, -0.86943305, -0.86...  ...   \n",
       "labels          [50258, 50259, 50359, 50363, 3322, 707, 1594, ...  ...   \n",
       "\n",
       "                                                               70  \\\n",
       "input_features  [[-0.84461737, -0.84461737, -0.84461737, -0.20...   \n",
       "labels          [50258, 50259, 50359, 50363, 270, 632, 257, 14...   \n",
       "\n",
       "                                                               71  \\\n",
       "input_features  [[-0.8953326, -0.8953326, -0.8953326, -0.89533...   \n",
       "labels          [50258, 50259, 50359, 50363, 2994, 412, 300, 5...   \n",
       "\n",
       "                                                               72  \\\n",
       "input_features  [[-0.7832053, -0.7832053, -0.5498072, 0.148869...   \n",
       "labels          [50258, 50259, 50359, 50363, 5616, 458, 689, 7...   \n",
       "\n",
       "                                                               73  \\\n",
       "input_features  [[-0.55103076, -0.55103076, -0.55103076, -0.55...   \n",
       "labels          [50258, 50259, 50359, 50363, 13162, 6576, 281,...   \n",
       "\n",
       "                                                               74  \\\n",
       "input_features  [[-0.5610559, -0.5610559, -0.5610559, -0.11793...   \n",
       "labels          [50258, 50259, 50359, 50363, 3322, 3295, 1194,...   \n",
       "\n",
       "                                                               75  \\\n",
       "input_features  [[-0.9255625, -0.9255625, -0.9255625, -0.92556...   \n",
       "labels          [50258, 50259, 50359, 50363, 3322, 3237, 5694,...   \n",
       "\n",
       "                                                               76  \\\n",
       "input_features  [[-0.82639194, -0.82639194, -0.82639194, -0.82...   \n",
       "labels          [50258, 50259, 50359, 50363, 266, 527, 636, 28...   \n",
       "\n",
       "                                                               77  \\\n",
       "input_features  [[-0.73914635, -0.73914635, -0.73914635, -0.57...   \n",
       "labels          [50258, 50259, 50359, 50363, 71, 3145, 732, 29...   \n",
       "\n",
       "                                                               78  \\\n",
       "input_features  [[-0.5983442, -0.5983442, -0.5983442, 0.034376...   \n",
       "labels          [50258, 50259, 50359, 50363, 20579, 456, 415, ...   \n",
       "\n",
       "                                                               79  \n",
       "input_features  [[-1.045434, -1.045434, -1.045434, -0.5077677,...  \n",
       "labels          [50258, 50259, 50359, 50363, 71, 3159, 82, 295...  \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = benchmark.T\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d4f52-7f80-4d07-91fd-673060f55f5c",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ea6049f-0719-46b8-96ba-d4766b24e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7388ffa5-bc82-4afa-ac56-294801b680cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.language = \"english\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fceb4e94-5351-49ee-81e6-1d2017aefc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12a27d9c-5201-4e12-8dca-81188efb3ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\modeling_whisper.py:697: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.732254047322541\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "from evaluate import load\n",
    "\n",
    "def map_to_pred(batch):\n",
    "    input_features = batch[\"input_features\"]\n",
    "    input_features = torch.from_numpy(input_features).float()\n",
    "    input_features = input_features.unsqueeze(0)\n",
    "    labels = batch[\"labels\"]\n",
    "    labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "    reference = processor.tokenizer.decode(labels, skip_special_tokens=True)\n",
    "    batch[\"reference\"] = processor.tokenizer._normalize(reference)\n",
    "    predicted_ids = model.to(\"cuda\").generate(input_features.to(\"cuda\"))[0]\n",
    "    prediction = processor.tokenizer.decode(predicted_ids, skip_special_tokens=True)\n",
    "    batch[\"prediction\"] = processor.tokenizer._normalize(prediction)\n",
    "    return batch\n",
    "\n",
    "result = benchmark.apply(map_to_pred)\n",
    "\n",
    "wer = load(\"wer\")\n",
    "print(100 * wer.compute(references=result.loc[\"reference\"], predictions=result.loc[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2de4bc-3a2e-4947-a5db-08605e85e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e175757e-88fd-4e20-aa9e-4927b6b813e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88c79d-7d82-4b19-8a7b-b0a7cd0034a2",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "245104ec-f723-421f-9ac3-45a469bf8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d2e2ab5-adb0-47ef-9a39-a461075d12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    with open('refs_and_preds.txt', 'w') as f:\n",
    "        for ref, pred in zip(label_str, pred_str):\n",
    "            f.write(f\"Ref: {ref}\\n\")\n",
    "            f.write(f\"Pred: {pred}\\n\\n\")\n",
    "    \n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f52c972-ae2f-473b-96e4-50562478a845",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3736f671-4117-4bab-9b7d-a9ef20e8ceb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-test\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=5e-8,\n",
    "    warmup_steps=250,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=400,\n",
    "    eval_steps=400,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "692c7b71-a6a8-4dba-b0ea-af6d1b4cbc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9ce3e3c-5474-4d01-9f9e-3438dc7ed927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a8533bb-a33f-40e2-abd2-509a5b4a7f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 21:03, Epoch 4000/4000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.920914</td>\n",
       "      <td>30.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.898984</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.895707</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.893053</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.892653</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.892668</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.891868</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.891186</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.891778</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.892117</td>\n",
       "      <td>15.384615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\torch\\utils\\checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=0.00693877083962434, metrics={'train_runtime': 1263.5001, 'train_samples_per_second': 101.306, 'train_steps_per_second': 3.166, 'total_flos': 2.30868320256e+18, 'train_loss': 0.00693877083962434, 'epoch': 4000.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c13cf972-9bb6-413a-9203-a026df9e969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lim_y\\anaconda3\\Lib\\site-packages\\transformers\\models\\whisper\\tokenization_whisper.py:501: UserWarning: The private method `_normalize` is deprecated and will be removed in v5 of Transformers.You can normalize an input string using the Whisper English normalizer using the `normalize` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.60772104607721\n"
     ]
    }
   ],
   "source": [
    "result = benchmark.apply(map_to_pred)\n",
    "\n",
    "wer = load(\"wer\")\n",
    "print(100 * wer.compute(references=result.loc[\"reference\"], predictions=result.loc[\"prediction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e782d5-fd27-4878-bb90-b514aa980732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lim_y\\anaconda3\\lib\\site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b649ace3-24b8-4721-aa9e-2647b1eb7da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b85adc2bbe4aefb9a4003f988f080f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b544a00b-c4cb-48b1-9306-4a0cc3383da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\n",
    "    \"dataset\": \"Common Voice 11.0\",  # a 'pretty' name for the training dataset\n",
    "    \"dataset_args\": \"config: en, split: test\",\n",
    "    \"language\": \"en\",\n",
    "    \"model_name\": \"Whisper Small Refined - Seagate Lim\",  # a 'pretty' name for your model\n",
    "    \"finetuned_from\": \"openai/whisper-small\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10bd2ca9-bf72-41be-ab8d-0ac33015bd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ae51508ef5448ca7d720609c2dd45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9dabd51ed494e339e970ee2f4e34b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20478ba679a54afcac2127a9c745f190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1723277552.LAPTOP-F12I3AC6.972.0:   0%|          | 0.00/9.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8547ac5c5148108638c39400a46097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1723277729.LAPTOP-F12I3AC6.972.1:   0%|          | 0.00/43.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8bfedd6d804067881ff220faf0c39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/PaidDatasetsBad/whisper-small-test/commit/4dae8ff56912d90eae7108526468d10b017fe070', commit_message='End of training', commit_description='', oid='4dae8ff56912d90eae7108526468d10b017fe070', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f159dc3-35d8-4c7f-a469-ec5ab01e3a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
